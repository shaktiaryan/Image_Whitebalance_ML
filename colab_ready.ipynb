{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a4c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Runtime check and mount Google Drive\n",
    "import sys, os\n",
    "print('Python:', sys.version)\n",
    "try:\n",
    "    import torch\n",
    "    print('Torch:', torch.__version__, 'CUDA available:', torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print('Device:', torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print('Torch import failed:', e)\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9c15d0",
   "metadata": {},
   "source": [
    "## Upload files from your local machine\n",
    "Use this cell to upload small files (CSVs, single images, or zips). For large datasets, keep files on Google Drive and use the Drive mount approach above.\n",
    "- Upload single files or multiple files via the file picker.\n",
    "- If you upload a ZIP of an image folder, the cell below will automatically unzip it into `data/Train` or `data/Validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69daa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b) Upload files directly from your computer (small files)\n",
    "from google.colab import files\n",
    "uploaded = files.upload()  # opens file picker\n",
    "\n",
    "import os, io, zipfile\n",
    "# Default destination (change if needed)\n",
    "train_dest = '/content/Image_Whitebalance_ML/data/Train'\n",
    "val_dest = '/content/Image_Whitebalance_ML/data/Validation'\n",
    "os.makedirs(train_dest, exist_ok=True)\n",
    "os.makedirs(val_dest, exist_ok=True)\n",
    "\n",
    "for fname, content in uploaded.items():\n",
    "    # If zip, extract intelligently. Otherwise save to Train by default.\n",
    "    lower = fname.lower()\n",
    "    if lower.endswith('.zip'):\n",
    "        # save zip then extract into Train folder (or specify)\n",
    "        zpath = os.path.join(train_dest, fname)\n",
    "        with open(zpath, 'wb') as f:\n",
    "            f.write(content)\n",
    "        try:\n",
    "            with zipfile.ZipFile(zpath, 'r') as z:\n",
    "                z.extractall(train_dest)\n",
    "            print(f'Extracted zip to {train_dest}')\n",
    "        except Exception as e:\n",
    "            print('Error extracting zip:', e)\n",
    "    else:\n",
    "        # Save non-zip files to Train by default. If you want Validation, move after upload.\n",
    "        dest = train_dest\n",
    "        out_path = os.path.join(dest, fname)\n",
    "        with open(out_path, 'wb') as f:\n",
    "            f.write(content)\n",
    "        print(f'Saved {fname} -> {out_path}')\n",
    "\n",
    "print('\n",
    "Upload complete. List /content/Image_Whitebalance_ML/data/Train (first 20 files):')\n",
    "!ls -la /content/Image_Whitebalance_ML/data/Train | head -n 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd921aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Clone the repository into Colab workspace\n",
    "!git clone https://github.com/shaktiaryan/Image_Whitebalance_ML.git /content/Image_Whitebalance_ML\n",
    "%cd /content/Image_Whitebalance_ML\n",
    "!git status --porcelain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07713860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Install dependencies (use pip; adjust torch wheel for your CUDA if needed)\n",
    "!pip install -r requirements.txt || true\n",
    "# If torch is not installed or the version mismatches, install the matching wheel. Example (uncomment if needed):\n",
    "# !pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fe3e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Optional: patch Windows paths in configs to Colab paths (safe operation)\n",
    "cfg_file = 'configs/base_config.py'\n",
    "import os\n",
    "if os.path.exists(cfg_file):\n",
    "    text = open(cfg_file, 'r', encoding='utf-8').read()\n",
    "    text = text.replace('E:\\\\aftershoot', '/content/Image_Whitebalance_ML')\n",
    "    open(cfg_file, 'w', encoding='utf-8').write(text)\n",
    "    print('Patched', cfg_file)\n",
    "else:\n",
    "    print(cfg_file, 'not present or already OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Prepare data: copy CSVs and link images from Google Drive (adjust your Drive path)\n",
    "import os\n",
    "os.makedirs('data/Train', exist_ok=True)\n",
    "os.makedirs('data/Validation', exist_ok=True)\n",
    "# Example: change these paths to where you stored dataset in Drive\n",
    "DRIVE_ROOT = '/content/drive/MyDrive/aftershoot_data'  # <- update if needed\n",
    "# Copy CSVs (fast)\n",
    "if os.path.exists(os.path.join(DRIVE_ROOT, 'Train', 'sliders_filtered.csv')):\n",
    "    !cp {DRIVE_ROOT}/Train/sliders_filtered.csv data/Train/sliders_filtered.csv\n",
    "else:\n",
    "    print('Train CSV not found in Drive path, please upload or change DRIVE_ROOT')\n",
    "# Symlink images directory to avoid full copy (if available)\n",
    "img_src = os.path.join(DRIVE_ROOT, 'Train', 'images')\n",
    "img_dst = 'data/Train/images'\n",
    "if os.path.exists(img_src) and not os.path.exists(img_dst):\n",
    "    !ln -s {img_src} {img_dst}\n",
    "    print('Created symlink to images')\n",
    "else:\n",
    "    print('Image source not found or destination exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Run EDA (generates visuals under outputs/eda)\n",
    "!python main.py --eda --config efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399cb32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Quick training smoke test (1 epoch)\n",
    "!python main.py --config lightweight --epochs 1 --device cuda --output_dir outputs/colab_test_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624e1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Full training example (when ready)\n",
    "# Uncomment and run when you have data and want a longer run\n",
    "# !python main.py --config lightweight --epochs 15 --device cuda --output_dir outputs/colab_full_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Run model testing (after a training run finishes)\n",
    "# !python test_model.py\n",
    "!python test_colab_model.py || true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890abcaa",
   "metadata": {},
   "source": [
    "---\n",
    "## Notes and caveats\n",
    "- Use pip (not Poetry) in Colab. Poetry is optional.\n",
    "- Keep large image data on Google Drive; symlink to avoid heavy copies.\n",
    "- If timm attempts to download pretrained weights, allow the download or pre-download to Drive.\n",
    "- If Colab runtime has no GPU, set `--device cpu`.\n",
    "---\n",
    "**Done**: run cells in order and check `outputs/*/logs/` and `outputs/*/logs/training_results.json`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
